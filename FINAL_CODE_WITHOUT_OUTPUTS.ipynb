{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZChF2inPa1K_"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab docs/BIO'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrA7LnIfa6ef"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1HgKqFSa1LA"
      },
      "source": [
        "# **Genomics of Drug Sensitivity in Cancer (GDSC) dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPHvGZwya1LB"
      },
      "source": [
        "The Genomics of Drug Sensitivity in Cancer (GDSC) dataset is a comprehensive resource designed for therapeutic biomarker discovery in cancer research. It contains drug response data, specifically the half-maximal inhibitory concentration (IC50) values, for a wide range of anti-cancer drugs tested on over a thousand human cancer cell lines. The features in this dataset include genomic profiles such as gene expression levels, mutation statuses, and copy number variations, alongside the corresponding drug identifiers and cancer types. The primary task is to predict drug sensitivity based on these genomic features, making it a regression problem where the target variable is the log-normalized IC50 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hecARmKSa1LB"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7edShlbcafN"
      },
      "outputs": [],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2ySmfw4a1LB"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy import stats\n",
        "from scipy.stats import skew, boxcox\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRkNiZ_wa1LB"
      },
      "source": [
        "# **1. Data Collection and Consolidation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaRTwhnVa1LC"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "gdsc_data = pd.read_csv('/content/drive/MyDrive/Colab docs/BIO/GDSC2-dataset.csv')\n",
        "cell_line_data = pd.read_excel('/content/drive/MyDrive/Colab docs/BIO/Cell_Lines_Details.xlsx', sheet_name='Cell line details')\n",
        "compound_data = pd.read_csv('/content/drive/MyDrive/Colab docs/BIO/Compounds-annotation.csv')\n",
        "\n",
        "# Display column names of each dataset to understand their structure\n",
        "print(gdsc_data.columns)\n",
        "print(cell_line_data.columns)\n",
        "print(compound_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxCgtCzMa1LC"
      },
      "source": [
        "**Columns of GDSC dataset:**\n",
        "1. **DATASET:** Identifier for the specific GDSC dataset version.\n",
        "2. **NLME_RESULT_ID:** Unique identifier for the non-linear mixed effects model result.\n",
        "3. **NLME_CURVE_ID:** Identifier for the dose-response curve fitted by NLME.\n",
        "4. **COSMIC_ID:** Unique identifier for the cell line from the COSMIC database.\n",
        "5. **CELL_LINE_NAME:** Name of the cancer cell line used in the experiment.\n",
        "6. **SANGER_MODEL_ID:** Identifier used by the Sanger Institute for the cell line model.\n",
        "7. **TCGA_DESC:** Description of the cancer type according to The Cancer Genome Atlas.\n",
        "8. **DRUG_ID:** Unique identifier for the drug used in the experiment.\n",
        "9. **DRUG_NAME:** Name of the drug used in the experiment.\n",
        "10. **PUTATIVE_TARGET:** The presumed molecular target of the drug.\n",
        "11. **PATHWAY_NAME:** The biological pathway affected by the drug.\n",
        "12. **COMPANY_ID:** Identifier for the company that provided the drug.\n",
        "13. **WEBRELEASE:** Date or version of web release for this data.\n",
        "14. **MIN_CONC:** Minimum concentration of the drug used in the experiment.\n",
        "15. **MAX_CONC:** Maximum concentration of the drug used in the experiment.\n",
        "16. **LN_IC50:** Natural log of the half-maximal inhibitory concentration (IC50).\n",
        "17. **AUC:** Area Under the Curve, a measure of drug effectiveness.\n",
        "18. **RMSE:** Root Mean Square Error, indicating the fit quality of the dose-response curve.\n",
        "19. **Z_SCORE:** Standardized score of the drug response, allowing comparison across different drugs and cell lines.\n",
        "\n",
        "These columns provide a comprehensive set of information about the drug sensitivity experiments, including identifiers for cell lines and drugs, experimental conditions, and various measures of drug response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgk5CyuZa1LC"
      },
      "source": [
        "**Columns of Cell Line Details:**\n",
        "1. **Sample Name:** Unique identifier for the cell line sample.\n",
        "2. **COSMIC identifier:** Unique ID from the COSMIC database for the cell line.\n",
        "3. **Whole Exome Sequencing (WES):** Genetic mutation data from whole exome sequencing.\n",
        "4. **Copy Number Alterations (CNA):** Data on gene copy number changes in the cell line.\n",
        "5. **Gene Expression:** Information on gene expression levels in the cell line.\n",
        "6. **Methylation:** Data on DNA methylation patterns in the cell line.\n",
        "7. **Drug Response:** Information on how the cell line responds to various drugs.\n",
        "8. **GDSC Tissue descriptor 1:** Primary tissue type classification.\n",
        "9. **GDSC Tissue descriptor 2:** Secondary tissue type classification.\n",
        "10. **Cancer Type (matching TCGA label):** Cancer type according to TCGA classification.\n",
        "11. **Microsatellite instability Status (MSI):** Indicates the cell line's MSI status.\n",
        "12. **Screen Medium:** The growth medium used for culturing the cell line.\n",
        "13. **Growth Properties:** Characteristics of how the cell line grows in culture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb_xfpxRa1LC"
      },
      "source": [
        "**Columns of Compounds Annotation:**\n",
        "1. **DRUG_ID:** Unique identifier for the drug.\n",
        "2. **SCREENING_SITE:** Location where the drug screening was performed.\n",
        "3. **DRUG_NAME:** Name of the drug compound.\n",
        "4. **SYNONYMS:** Alternative names for the drug.\n",
        "5. **TARGET:** The molecular target(s) of the drug.\n",
        "6. **TARGET_PATHWAY:** The biological pathway(s) targeted by the drug.\n",
        "\n",
        "These columns provide detailed information about the cell lines used in the experiments and the drugs tested, including genomic characteristics, growth conditions, and drug properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLpyLTKua1LC"
      },
      "outputs": [],
      "source": [
        "# For GDSC2-dataset, keep these columns:\n",
        "gdsc_columns = ['COSMIC_ID', 'CELL_LINE_NAME', 'TCGA_DESC', 'DRUG_ID', 'DRUG_NAME',\n",
        "                'PUTATIVE_TARGET', 'PATHWAY_NAME', 'LN_IC50', 'AUC', 'Z_SCORE']\n",
        "\n",
        "# For Cell-line-data, we'll join on 'COSMIC identifier' and keep:\n",
        "cell_columns = ['COSMIC identifier', 'Sample Name', 'GDSC\\nTissue descriptor 1',\n",
        "                'GDSC\\nTissue\\ndescriptor 2', 'Cancer Type\\n(matching TCGA label)',\n",
        "                'Microsatellite \\ninstability Status (MSI)', 'Screen Medium', 'Growth Properties',\n",
        "                'Whole Exome Sequencing (WES)','Copy Number Alterations (CNA)', 'Gene Expression', 'Methylation']\n",
        "\n",
        "# For Compounds-annotation, we'll join on 'DRUG_ID' and keep:\n",
        "compound_columns = ['DRUG_ID', 'TARGET', 'TARGET_PATHWAY']\n",
        "\n",
        "# Select relevant columns\n",
        "gdsc_data = gdsc_data[gdsc_columns]\n",
        "cell_line_data = cell_line_data[cell_columns]\n",
        "compound_data = compound_data[compound_columns]\n",
        "\n",
        "# Rename columns for consistency\n",
        "cell_line_data = cell_line_data.rename(columns={'COSMIC identifier': 'COSMIC_ID', 'Sample Name': 'CELL_LINE_NAME' ,\n",
        "                                                'GDSC\\nTissue descriptor 1':'GDSC Tissue descriptor 1',\n",
        "                                                'GDSC\\nTissue\\ndescriptor 2':'GDSC Tissue descriptor 2',\n",
        "                                                'Cancer Type\\n(matching TCGA label)':'Cancer Type (matching TCGA label)',\n",
        "                                                'Microsatellite \\ninstability Status (MSI)':'Microsatellite instability Status (MSI)',\n",
        "                                                'Whole Exome Sequencing (WES)': 'WES',\n",
        "                                                'Copy Number Alterations (CNA)': 'CNA'\n",
        "                                               })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DoOOWea1LC"
      },
      "source": [
        "## 1.1. Merging Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sicE95Jpa1LC"
      },
      "outputs": [],
      "source": [
        "# Merge GDSC2-dataset with Cell-line-annotation\n",
        "merged_data = pd.merge(gdsc_data, cell_line_data, on=['COSMIC_ID', 'CELL_LINE_NAME'], how='left')\n",
        "\n",
        "# Merge with Compounds-annotation\n",
        "final_data = pd.merge(merged_data, compound_data, on='DRUG_ID', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7XSLzC1a1LC"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the final dataset\n",
        "print(final_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAAR-jK1a1LC"
      },
      "source": [
        "## 1.2. Check for Duplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_5IaUuQa1LC"
      },
      "outputs": [],
      "source": [
        "duplicated_rows = final_data.duplicated()\n",
        "sum(duplicated_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntDh2pqba1LD"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows to verify the merge\n",
        "final_data.head(2).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jyReDCFa1LD"
      },
      "source": [
        "## 1.3. Remove Redundant Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP37w02Na1LD"
      },
      "outputs": [],
      "source": [
        "GDSC_DATASET = final_data.drop(columns=['PUTATIVE_TARGET','PATHWAY_NAME','WES'], index=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E28xKmIa1LD"
      },
      "outputs": [],
      "source": [
        "GDSC_DATASET.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HPiqOt3a1LD"
      },
      "outputs": [],
      "source": [
        "GDSC_DATASET.to_csv('GDSC_DATASET.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6SG2h0Ya1LD"
      },
      "source": [
        "# 2. Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oewGB1bEa1LD"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "Data = pd.read_csv('/content/drive/MyDrive/Colab docs/BIO/GDSC_DATASET.csv')\n",
        "\n",
        "# Display column names of each dataset to understand their structure\n",
        "print(Data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnPpw-3ea1LD"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the GDSC dataset\n",
        "print(Data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WhzE2Cga1LD"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of Dataset\n",
        "Data.head().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "furZstyMa1LD"
      },
      "outputs": [],
      "source": [
        "#some information about the attributes(datatypes & null values)\n",
        "Data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQGoJWrEa1LD"
      },
      "outputs": [],
      "source": [
        "# Check statistical information of Numeric Features\n",
        "\n",
        "numeric_features = Data.select_dtypes(include=[np.number])\n",
        "Data.describe(include=[np.number]).transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dop0rLUca1LD"
      },
      "outputs": [],
      "source": [
        "# Check statistical information of Categorical Features\n",
        "\n",
        "categorical_features = Data.select_dtypes(include=object)\n",
        "Data.describe(include=object).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg4cxEqla1LD"
      },
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy1Zp_Bna1LD"
      },
      "source": [
        "## 3.1. Duplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cWvviUYa1LD"
      },
      "outputs": [],
      "source": [
        "duplicated_rows = Data.duplicated()\n",
        "sum(duplicated_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VoIeYaTa1LE"
      },
      "source": [
        "## 3.2. Unique Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0-1AwMJa1LE"
      },
      "outputs": [],
      "source": [
        "# Get the number of unique values for each column\n",
        "unique_counts = Data.nunique()\n",
        "print(unique_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ADg1vX2xa1LE"
      },
      "outputs": [],
      "source": [
        "# Set a threshold for the maximum number of unique values to display frequencies\n",
        "threshold = 1000\n",
        "\n",
        "# Dictionary to hold value frequencies\n",
        "value_frequencies = {}\n",
        "\n",
        "# Iterate over columns to compute value frequencies\n",
        "for col in Data.columns:\n",
        "    if unique_counts[col] <= threshold:\n",
        "        value_counts = Data[col].value_counts()\n",
        "        value_frequencies[col] = value_counts\n",
        "\n",
        "# Print the value frequencies for columns with fewer unique values\n",
        "for col, frequencies in value_frequencies.items():\n",
        "    print(f\"Column '{col}':\")\n",
        "    print(f\"Number of unique values: {unique_counts[col]}\")\n",
        "    print(\"Value frequencies:\")\n",
        "    print(frequencies)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LocYPDpLa1LE"
      },
      "outputs": [],
      "source": [
        "def get_unique_counts_by_drug(df):\n",
        "    unique_counts = {}\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique():\n",
        "        drug_data = df[df['DRUG_NAME'] == drug]\n",
        "        unique_counts[drug] = drug_data.nunique()\n",
        "\n",
        "    return unique_counts\n",
        "\n",
        "# Get the unique counts for each drug\n",
        "drug_unique_counts = get_unique_counts_by_drug(Data)\n",
        "\n",
        "# Print the results\n",
        "for drug, counts in drug_unique_counts.items():\n",
        "    print(f\"\\nUnique counts for {drug}:\")\n",
        "    print(counts)\n",
        "    print(\"-\" * 50)  # Separator for readability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnpxkeYaa1LE"
      },
      "source": [
        "### 3.2.1. DRUG_ID and DRUG_NAME discrepancy:\n",
        "The difference in unique counts between DRUG_ID (295) and DRUG_NAME (286) suggests that some drugs might have multiple IDs or there might be some inconsistencies in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Rfza6Ta1LE"
      },
      "outputs": [],
      "source": [
        "drug_mapping = Data[['DRUG_ID', 'DRUG_NAME']].drop_duplicates()\n",
        "duplicates = drug_mapping[drug_mapping.duplicated('DRUG_NAME', keep=False)]\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMdM1Dma1LE"
      },
      "source": [
        "During our data preparation, we noticed that some drugs in the GDSC dataset have more than one DRUG_ID for the same DRUG_NAME. We looked into this and found that even with different IDs, these drugs have the same TARGET and TARGET_PATHWAY information. To keep things simple and clear, we decided to use DRUG_NAME as our main way to identify drugs in our analysis. This approach helps us avoid confusion while still keeping all the important drug information intact. We've kept a record of how the original DRUG_IDs match up with DRUG_NAMEs, but we'll mainly use DRUG_NAME in our analysis to keep everything consistent and easy to understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj-F2hXAa1LE"
      },
      "source": [
        "## 3.3. Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsbl3SHPa1LH"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(Data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWAtbi7ca1LI"
      },
      "outputs": [],
      "source": [
        "def check_missing_values_by_drug(df):\n",
        "    missing_values = {}\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique():\n",
        "        drug_data = df[df['DRUG_NAME'] == drug]\n",
        "        missing_values[drug] = drug_data.isnull().sum()\n",
        "\n",
        "    return missing_values\n",
        "\n",
        "# Assuming your DataFrame is named 'Data'\n",
        "drug_missing_values = check_missing_values_by_drug(Data)\n",
        "\n",
        "# Print the results\n",
        "for drug, missing_counts in drug_missing_values.items():\n",
        "    print(f\"\\nMissing values for {drug}:\")\n",
        "    print(missing_counts)\n",
        "    print(f\"Total missing values: {missing_counts.sum()}\")\n",
        "    print(\"-\" * 50)  # Separator for readability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ-wbQ-qa1LI"
      },
      "source": [
        "## 3.4. **Missing Value Handling in GDSC Dataset: A Drug-by-Drug Approach**\n",
        "\n",
        "Our method for handling missing values in the GDSC dataset is implemented on a drug-by-drug basis. This approach is crucial because:\n",
        "\n",
        "1. Different drugs may have unique patterns of missing data.\n",
        "2. Drug-specific biological mechanisms can influence how missing values should be imputed.\n",
        "3. It allows for more precise imputation by considering drug-specific relationships between features.\n",
        "\n",
        "Let's break down each step of our approach:\n",
        "\n",
        "### 1. Tissue Descriptors and Cancer Type Handling\n",
        "\n",
        "**Why**: Tissue and cancer type information is fundamental to understanding drug response variability across different biological contexts.\n",
        "\n",
        "**How**: We impute missing values using related tissue information within each drug subset. This preserves the biological relevance of the imputed values and maintains consistency across related tissue descriptors.\n",
        "\n",
        "### 2. TARGET and TARGET_PATHWAY Handling\n",
        "\n",
        "**Why**: These features are crucial for understanding a drug's mechanism of action, which is typically consistent across samples for a given drug.\n",
        "\n",
        "**How**: If all values are missing for a drug, we label it as 'Unknown for this drug'. Otherwise, we use the known value for that specific drug, ensuring consistency in the drug's molecular target information.\n",
        "\n",
        "### 3. Other Categorical Variables\n",
        "\n",
        "**Why**: Features like MSI status, screen medium, and growth properties can significantly influence drug response and are often related to tissue type.\n",
        "\n",
        "**How**: We impute based on the most common value within the same primary tissue type for each drug. This maintains the biological relationship between these properties and tissue types.\n",
        "\n",
        "### 4. Genomic Features Handling\n",
        "\n",
        "**Why**: Genomic features (CNA, Gene Expression, Methylation) are key determinants of drug response and can vary significantly across tissue types.\n",
        "\n",
        "**How**: We first attempt to impute based on tissue type within each drug subset. If missing values persist, we use KNN imputation, which can capture more complex relationships in the genomic data.\n",
        "\n",
        "### 5. Numeric Variables Handling\n",
        "\n",
        "**Why**: Variables like LN_IC50, AUC, and Z_SCORE directly measure drug response and are critical for downstream analyses.\n",
        "\n",
        "**How**: We use Random Forest imputation when sufficient data is available, leveraging the complex relationships between genomic features, tissue types, and drug response. For drugs with limited data, we fall back to median imputation grouped by tissue type.\n",
        "\n",
        "This drug-by-drug approach ensures that we:\n",
        "1. Preserve drug-specific patterns and relationships in the data.\n",
        "2. Account for the unique biological context of each drug's action.\n",
        "3. Maintain consistency in drug-related information across samples.\n",
        "4. Leverage the most appropriate imputation method based on data availability for each drug.\n",
        "\n",
        "By combining biological knowledge with advanced statistical techniques, this method provides a robust and biologically relevant solution to missing data in the GDSC dataset, setting a strong foundation for subsequent analyses and drug response predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhLGxVvKa1LI"
      },
      "outputs": [],
      "source": [
        "def handle_missing_values_by_drug(df):\n",
        "    knn_imputer = KNNImputer(n_neighbors=5)\n",
        "    numeric_imputers = {}\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique():\n",
        "        drug_data = df[df['DRUG_NAME'] == drug].copy()\n",
        "\n",
        "        # 1. Tissue Descriptors and Cancer Type Handling\n",
        "        tissue_cols = ['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2', 'Cancer Type (matching TCGA label)', 'TCGA_DESC']\n",
        "        for col in tissue_cols:\n",
        "            if drug_data[col].isnull().any():\n",
        "                # Impute based on other tissue information\n",
        "                for other_col in [c for c in tissue_cols if c != col]:\n",
        "                    drug_data[col] = drug_data.groupby(other_col)[col].transform(\n",
        "                        lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Unknown')\n",
        "                    )\n",
        "                # If still null, use overall mode\n",
        "                drug_data[col] = drug_data[col].fillna(drug_data[col].mode()[0] if not drug_data[col].mode().empty else 'Unknown')\n",
        "\n",
        "        # 2. TARGET Handling\n",
        "        if drug_data['TARGET'].isnull().all():\n",
        "            drug_data['TARGET'] = 'Unknown for this drug'\n",
        "        else:\n",
        "            known_target = drug_data['TARGET'].dropna().iloc[0]\n",
        "            drug_data['TARGET'] = drug_data['TARGET'].fillna(known_target)\n",
        "\n",
        "        # 2. TARGET_PATHWAY Handling\n",
        "        if drug_data['TARGET_PATHWAY'].isnull().all():\n",
        "            drug_data['TARGET_PATHWAY'] = 'Unknown for this drug'\n",
        "        else:\n",
        "            known_pathway = drug_data['TARGET_PATHWAY'].dropna().iloc[0]\n",
        "            drug_data['TARGET_PATHWAY'] = drug_data['TARGET_PATHWAY'].fillna(known_pathway)\n",
        "\n",
        "        # 3. Other Categorical Variables\n",
        "        other_categorical_cols = ['Microsatellite instability Status (MSI)', 'Screen Medium', 'Growth Properties']\n",
        "        for col in other_categorical_cols:\n",
        "            drug_data[col] = drug_data.groupby('GDSC Tissue descriptor 1')[col].transform(\n",
        "                lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Unknown')\n",
        "            )\n",
        "\n",
        "        # 4. Genomic Features Handling\n",
        "        genomic_features = ['CNA', 'Gene Expression', 'Methylation']\n",
        "        for feature in genomic_features:\n",
        "            if drug_data[feature].isnull().any():\n",
        "                # First, try to impute based on tissue type\n",
        "                drug_data[feature] = drug_data.groupby(['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2'])[feature].transform(\n",
        "                    lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan)\n",
        "                )\n",
        "                # If still null, use KNN imputation\n",
        "                if drug_data[feature].isnull().any():\n",
        "                    feature_data = pd.get_dummies(drug_data[feature], prefix=feature)\n",
        "                    imputed_data = knn_imputer.fit_transform(feature_data)\n",
        "                    imputed_df = pd.DataFrame(imputed_data, columns=feature_data.columns, index=feature_data.index)\n",
        "                    drug_data[feature] = imputed_df.idxmax(axis=1).str.split('_').str[1]\n",
        "\n",
        "        # 5. Numeric Variables Handling\n",
        "        numeric_cols = ['LN_IC50', 'AUC', 'Z_SCORE']\n",
        "\n",
        "        # Prepare features for imputation\n",
        "        features_for_imputation = pd.get_dummies(drug_data[genomic_features + ['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2']])\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            if drug_data[col].isnull().any():\n",
        "                if col not in numeric_imputers:\n",
        "                    numeric_imputers[col] = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "                available_data = drug_data.dropna(subset=[col])\n",
        "                if len(available_data) > 10:\n",
        "                    X_train = features_for_imputation.loc[available_data.index]\n",
        "                    y_train = available_data[col]\n",
        "                    numeric_imputers[col].fit(X_train, y_train)\n",
        "\n",
        "                    missing_data = drug_data[drug_data[col].isnull()]\n",
        "                    X_missing = features_for_imputation.loc[missing_data.index]\n",
        "                    drug_data.loc[drug_data[col].isnull(), col] = numeric_imputers[col].predict(X_missing)\n",
        "                else:\n",
        "                    # If not enough data, use median grouped by tissue type\n",
        "                    drug_data[col] = drug_data.groupby(['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2'])[col].transform(\n",
        "                        lambda x: x.fillna(x.median())\n",
        "                    )\n",
        "\n",
        "        df.loc[df['DRUG_NAME'] == drug] = drug_data\n",
        "\n",
        "    return df\n",
        "\n",
        "Data = handle_missing_values_by_drug(Data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgjgiiH3a1LI"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(Data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li0TZvR4a1LI"
      },
      "source": [
        "## 3.5. Encoding Categorical Features:\n",
        "\n",
        "Given the high cardinality of some features, we'll use a combination of encoding techniques:\n",
        "\n",
        "* Simple binary encoding for features with 2 unique values\n",
        "* One-hot encoding for low-cardinality features (3 unique values)\n",
        "* Target encoding for high-cardinality features\n",
        "* Label encoding for ordinal features (IDs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_8a847Xa1LI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from category_encoders import TargetEncoder\n",
        "import pandas as pd\n",
        "\n",
        "def encode_features(df, target_column='LN_IC50'):\n",
        "    # Identify features with only two unique values\n",
        "    binary_features = [col for col in df.columns if df[col].nunique() == 2]\n",
        "\n",
        "    # Binary encoding for features with two unique values\n",
        "    for feature in binary_features:\n",
        "        df[feature] = (df[feature] == df[feature].unique()[0]).astype(int)\n",
        "\n",
        "    # One-hot encoding for low-cardinality features (3 unique values)\n",
        "    onehot_features = ['Growth Properties']\n",
        "    onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    onehot_encoded = onehot_encoder.fit_transform(df[onehot_features])\n",
        "\n",
        "    # Use get_feature_names_out to get the names of the one-hot encoded features\n",
        "    onehot_columns = onehot_encoder.get_feature_names_out(onehot_features)\n",
        "    df_onehot = pd.DataFrame(onehot_encoded, columns=onehot_columns, index=df.index)\n",
        "\n",
        "    # Target encoding for high-cardinality features\n",
        "    target_features = ['TCGA_DESC', 'DRUG_NAME', 'GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2',\n",
        "                       'Cancer Type (matching TCGA label)', 'TARGET', 'TARGET_PATHWAY']\n",
        "    target_encoder = TargetEncoder()\n",
        "    df_target_encoded = target_encoder.fit_transform(df[target_features], df[target_column])\n",
        "\n",
        "    # Label encoding for DRUG_ID and COSMIC_ID\n",
        "    label_features = ['DRUG_ID', 'COSMIC_ID', 'CELL_LINE_NAME']\n",
        "    label_encoder = LabelEncoder()\n",
        "    df_label_encoded = df[label_features].apply(label_encoder.fit_transform)\n",
        "\n",
        "    # Combine all encoded features\n",
        "    df_encoded = pd.concat([df[binary_features], df_onehot, df_target_encoded, df_label_encoded], axis=1)\n",
        "\n",
        "    return df_encoded\n",
        "\n",
        "encoded_data = encode_features(Data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APC9LakSa1LI"
      },
      "outputs": [],
      "source": [
        "print(encoded_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LGAF0l7a1LI"
      },
      "outputs": [],
      "source": [
        "print(Data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dThtzzKaa1LI"
      },
      "outputs": [],
      "source": [
        "encoded_data['LN_IC50']=Data['LN_IC50']\n",
        "encoded_data['AUC']=Data['AUC']\n",
        "encoded_data['Z_SCORE']=Data['Z_SCORE']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "junneRNHa1LI"
      },
      "source": [
        "# 4. Visualization Gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_bf3Vda1LI"
      },
      "source": [
        "## 4.1. Distribution of Numeric Features\n",
        "\n",
        "This interactive plot shows the distribution of key numeric features in our dataset: LN_IC50 (drug sensitivity), AUC (area under the curve), and Z_SCORE. The histograms provide an overview of the data distribution, while the scatter points below each histogram show the actual data points, allowing for a detailed examination of the data spread and potential outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3DKEWS0a1LI"
      },
      "outputs": [],
      "source": [
        "def plot_numeric_features(df, numeric_cols):\n",
        "    fig = make_subplots(rows=1, cols=3, subplot_titles=numeric_cols)\n",
        "\n",
        "    for i, col in enumerate(numeric_cols, 1):\n",
        "        fig.add_trace(\n",
        "            go.Histogram(x=df[col], name=col, marker_color='#4169E1', opacity=0.7),\n",
        "            row=1, col=i\n",
        "        )\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=df[col], y=[0]*len(df), mode='markers',\n",
        "                       marker=dict(color='#4169E1', symbol='line-ns-open'), name='Data points'),\n",
        "            row=1, col=i\n",
        "        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=\"Distribution of Key Numeric Features\",\n",
        "        height=500, width=1200,\n",
        "        showlegend=False\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "numeric_cols = ['LN_IC50', 'AUC', 'Z_SCORE']\n",
        "plot_numeric_features(Data, numeric_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMOEAviZa1LJ"
      },
      "source": [
        "## 4.2. GDSC Tissue Distribution\n",
        "\n",
        "This horizontal bar chart displays the distribution of the top 20 tissue types in our GDSC dataset. It provides a clear visualization of the most common cancer tissues studied, which is crucial for understanding the focus areas of the drug sensitivity experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QK8yp4Ka1LJ"
      },
      "outputs": [],
      "source": [
        "def plot_gdsc_tissue_distribution(data):\n",
        "    tissue_counts = data['GDSC Tissue descriptor 1'].value_counts().nlargest(20)\n",
        "\n",
        "    fig = go.Figure(go.Bar(\n",
        "        x=tissue_counts.values,\n",
        "        y=tissue_counts.index,\n",
        "        orientation='h',\n",
        "        marker_color='#4169E1'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Top 20 GDSC Tissue Types',\n",
        "        xaxis_title='Count',\n",
        "        yaxis_title='Tissue Type',\n",
        "        height=600,\n",
        "        width=1000\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_gdsc_tissue_distribution(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRxEguF9a1LJ"
      },
      "source": [
        "## 4.3. Pairplot of Numeric Features\n",
        "\n",
        "This pairplot matrix shows the relationships between our key numeric features: LN_IC50, AUC, and Z_SCORE. The diagonal plots show the distribution of each feature, while the off-diagonal plots show the relationships between pairs of features. This visualization helps in identifying correlations and patterns among these important drug sensitivity metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF7yt91ka1LJ"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "\n",
        "pyo.init_notebook_mode(connected=True)\n",
        "\n",
        "def plot_numeric_pairplot(data, numeric_cols, sample_size=1000):\n",
        "    # Sample the data to reduce plot size\n",
        "    if len(data) > sample_size:\n",
        "        data = data.sample(sample_size, random_state=42)\n",
        "\n",
        "    fig = make_subplots(rows=3, cols=3, subplot_titles=[f\"{x} vs {y}\" for x in numeric_cols for y in numeric_cols])\n",
        "\n",
        "    for i, x in enumerate(numeric_cols, 1):\n",
        "        for j, y in enumerate(numeric_cols, 1):\n",
        "            if x == y:\n",
        "                trace = go.Histogram(x=data[x], name=x, marker_color='#4169E1', opacity=0.7)\n",
        "            else:\n",
        "                trace = go.Scatter(x=data[x], y=data[y], mode='markers',\n",
        "                                   marker=dict(color='#4169E1', size=3, opacity=0.5),\n",
        "                                   name=f\"{x} vs {y}\")\n",
        "            fig.add_trace(trace, row=i, col=j)\n",
        "\n",
        "    fig.update_layout(height=900, width=900, title_text=\"Pairplot of Numeric Features\")\n",
        "\n",
        "    # Update axes labels\n",
        "    for i, col in enumerate(numeric_cols):\n",
        "        fig.update_xaxes(title_text=col, row=3, col=i+1)\n",
        "        fig.update_yaxes(title_text=col, row=i+1, col=1)\n",
        "\n",
        "    # Use iplot for inline plotting\n",
        "    pyo.iplot(fig)\n",
        "\n",
        "\n",
        "plot_numeric_pairplot(Data, ['LN_IC50', 'AUC', 'Z_SCORE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sR0etoca1LJ"
      },
      "source": [
        "## 4.4. Drug Sensitivity Across Cancer Types\n",
        "\n",
        "This boxplot illustrates the variation in drug sensitivity (LN_IC50) across different cancer types. The cancer types are ordered by median LN_IC50 values, allowing for easy comparison of drug responsiveness among different cancers. This visualization is crucial for identifying cancer types that may be more or less responsive to the drugs in our dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odwxsui1a1LJ"
      },
      "outputs": [],
      "source": [
        "def plot_drug_sensitivity_by_cancer(data):\n",
        "    cancer_types = data.groupby('Cancer Type (matching TCGA label)')['LN_IC50'].median().sort_values(ascending=False)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Box(\n",
        "        y=data['LN_IC50'],\n",
        "        x=data['Cancer Type (matching TCGA label)'],\n",
        "        name='LN_IC50',\n",
        "        marker_color='#4169E1'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Distribution of Drug Sensitivity Across Cancer Types',\n",
        "        xaxis_title='Cancer Type',\n",
        "        yaxis_title='LN_IC50',\n",
        "        height=600,\n",
        "        width=1200,\n",
        "        xaxis={'categoryorder':'array', 'categoryarray':cancer_types.index}\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_drug_sensitivity_by_cancer(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYJQu2vKa1LJ"
      },
      "source": [
        "## 4.5. Drug Efficacy Across Tissue Types\n",
        "\n",
        "This boxplot shows how drug efficacy (AUC) varies across different tissue types. The tissue types are ordered by median AUC values, providing insights into tissue-specific drug responses. This visualization is essential for understanding which tissue types tend to be more responsive to the drugs in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYJkjoaha1LJ"
      },
      "outputs": [],
      "source": [
        "def plot_drug_efficacy_by_tissue(data):\n",
        "    tissue_types = data.groupby('GDSC Tissue descriptor 1')['AUC'].median().sort_values(ascending=False)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Box(\n",
        "        y=data['AUC'],\n",
        "        x=data['GDSC Tissue descriptor 1'],\n",
        "        name='AUC',\n",
        "        marker_color='#4169E1'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Drug Efficacy Across Different Tissue Types',\n",
        "        xaxis_title='Tissue Type',\n",
        "        yaxis_title='AUC',\n",
        "        height=600,\n",
        "        width=1200,\n",
        "        xaxis={'categoryorder':'array', 'categoryarray':tissue_types.index}\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_drug_efficacy_by_tissue(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3qNMB66a1LK"
      },
      "source": [
        "## 4.6. Top Drug Targets\n",
        "\n",
        "This horizontal bar chart highlights the top 10 most common drug targets in our dataset. Understanding the frequency of different drug targets provides insights into the focus areas of drug development and the molecular pathways being targeted in cancer treatment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_OOYx3ka1LK"
      },
      "outputs": [],
      "source": [
        "def plot_top_drug_targets(data):\n",
        "    top_targets = data['TARGET'].value_counts().nlargest(10)\n",
        "\n",
        "    fig = go.Figure(go.Bar(\n",
        "        x=top_targets.values,\n",
        "        y=top_targets.index,\n",
        "        orientation='h',\n",
        "        marker_color='#4169E1'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Top 10 Drug Targets',\n",
        "        xaxis_title='Count',\n",
        "        yaxis_title='Target',\n",
        "        height=500,\n",
        "        width=900\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_top_drug_targets(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkHe0WBZa1LM"
      },
      "source": [
        "## 4.7. Distribution of Target Pathways\n",
        "\n",
        "This horizontal bar chart shows the distribution of different target pathways in our dataset. It provides a clear view of which cellular pathways are most frequently targeted by the drugs in our study, offering insights into the mechanisms of action being explored in cancer treatment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LRRxrbKa1LM"
      },
      "outputs": [],
      "source": [
        "def plot_target_pathways(data):\n",
        "    pathway_counts = data['TARGET_PATHWAY'].value_counts()\n",
        "\n",
        "    fig = go.Figure(go.Bar(\n",
        "        x=pathway_counts.values,\n",
        "        y=pathway_counts.index,\n",
        "        orientation='h',\n",
        "        marker_color='#4169E1'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Distribution of Target Pathways',\n",
        "        xaxis_title='Count',\n",
        "        yaxis_title='Target Pathway',\n",
        "        height=600,\n",
        "        width=1000\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_target_pathways(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpJGwt3Ra1LM"
      },
      "source": [
        "## 4.8. Impact of Microsatellite Instability on Drug Response\n",
        "\n",
        "This boxplot illustrates how microsatellite instability (MSI) status affects drug response (LN_IC50). The plot includes individual data points, allowing for a detailed view of the data distribution. This visualization is crucial for understanding the relationship between MSI status and drug sensitivity, which has important implications for personalized cancer treatment strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT1OjNwqa1LM"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "import plotly.offline as pyo\n",
        "import pandas as pd\n",
        "\n",
        "pyo.init_notebook_mode(connected=True)\n",
        "\n",
        "def plot_msi_impact(data, sample_size=10000):\n",
        "    # Sample the data if it's too large\n",
        "    if len(data) > sample_size:\n",
        "        data = data.sample(sample_size, random_state=42)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Create a mapping for MSI status\n",
        "    msi_mapping = {0: 'MSS/MSI-L', 1: 'MSI-H'}\n",
        "\n",
        "    for msi_status in data['Microsatellite instability Status (MSI)'].unique():\n",
        "        msi_label = msi_mapping.get(msi_status, str(msi_status))\n",
        "        msi_data = data[data['Microsatellite instability Status (MSI)'] == msi_status]['LN_IC50']\n",
        "\n",
        "        # Calculate summary statistics\n",
        "        q1, median, q3 = msi_data.quantile([0.25, 0.5, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        whisker_low, whisker_high = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
        "\n",
        "        fig.add_trace(go.Box(\n",
        "            y=msi_data,\n",
        "            name=msi_label,\n",
        "            boxpoints='outliers',  # Only show outliers\n",
        "            jitter=0.3,\n",
        "            pointpos=-1.8,\n",
        "            lowerfence=[whisker_low],  # Wrap in list\n",
        "            upperfence=[whisker_high],  # Wrap in list\n",
        "            q1=[q1],\n",
        "            median=[median],\n",
        "            q3=[q3]\n",
        "        ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Impact of Microsatellite Instability Status on Drug Response',\n",
        "        xaxis_title='MSI Status',\n",
        "        yaxis_title='LN_IC50',\n",
        "        height=500,\n",
        "        width=800\n",
        "    )\n",
        "\n",
        "    # Use iplot for inline plotting\n",
        "    pyo.iplot(fig)\n",
        "\n",
        "plot_msi_impact(encoded_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvNX_JHga1LM"
      },
      "outputs": [],
      "source": [
        "def plot_msi_impact(data, sample_size=50000):\n",
        "    # Sample the data if it's too large\n",
        "    if len(data) > sample_size:\n",
        "        data = data.sample(sample_size, random_state=42)\n",
        "\n",
        "    # Create a mapping for MSI status\n",
        "    msi_mapping = {0: 'MSS/MSI-L', 1: 'MSI-H'}\n",
        "\n",
        "    # Apply the mapping to create a new column\n",
        "    data['MSI_Status'] = data['Microsatellite instability Status (MSI)'].map(msi_mapping)\n",
        "\n",
        "    # Set up the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Create the boxplot\n",
        "    sns.boxplot(x='MSI_Status', y='LN_IC50', data=data, palette='Set3')\n",
        "\n",
        "    # Add strip plot for individual points\n",
        "    sns.stripplot(x='MSI_Status', y='LN_IC50', data=data, color='black', alpha=0.1, size=2)\n",
        "\n",
        "    # Customize the plot\n",
        "    plt.title('Impact of Microsatellite Instability Status on Drug Response', fontsize=16)\n",
        "    plt.xlabel('MSI Status', fontsize=12)\n",
        "    plt.ylabel('LN_IC50', fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the function\n",
        "plot_msi_impact(encoded_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eid_MZXfa1LM"
      },
      "source": [
        "## 4.9. Treemap of GDSC Tissue Descriptors\n",
        "\n",
        "This interactive treemap visualizes the hierarchical relationship between GDSC Tissue descriptor 1 (main tissues) and GDSC Tissue descriptor 2 (sub-tissues). The size of each box represents the count of samples in that category, while the color intensity indicates the relative proportion. Hover over each box to see detailed information including the tissue name, count, and percentage within its parent category. This visualization provides a comprehensive overview of the tissue distribution in our dataset, highlighting both the main tissue types and their subtypes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Dm39BEa1a1LM"
      },
      "outputs": [],
      "source": [
        "# Prepare data for treemap\n",
        "df_grouped = Data.groupby(['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2']).size().reset_index(name='count')\n",
        "\n",
        "# Inspect the grouped DataFrame\n",
        "print(\"Grouped DataFrame:\")\n",
        "print(df_grouped)\n",
        "\n",
        "# Check if the grouped DataFrame is empty\n",
        "if df_grouped.empty:\n",
        "    print(\"Error: Grouping resulted in an empty DataFrame.\")\n",
        "else:\n",
        "    print(\"Grouped DataFrame is not empty. Rows:\", len(df_grouped))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrLHHesia1LN"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "def plot_tissue_treemap(data):\n",
        "    df_grouped = data.groupby(['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2']).size().reset_index(name='count')\n",
        "\n",
        "    fig = px.treemap(df_grouped,\n",
        "                     path=['GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2'],\n",
        "                     values='count',\n",
        "                     color='count',\n",
        "                     color_continuous_scale='Blues',\n",
        "                     title='Hierarchical View of GDSC Tissue Descriptors')\n",
        "\n",
        "    fig.update_layout(width=1000, height=800)\n",
        "    fig.show()\n",
        "\n",
        "plot_tissue_treemap(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQdp06HDa1LN"
      },
      "source": [
        "## 4.10. Sunburst Chart for Cancer Types and Growth Properties\n",
        "\n",
        "This sunburst chart illustrates the relationship between cancer types and their growth properties. Each ring represents a level in the hierarchy: the inner ring shows cancer types, while the outer ring displays the growth properties for each cancer type. The size and color of each segment represent the count of samples. This visualization helps in understanding the distribution of growth properties across different cancer types, which can be crucial for understanding cancer behavior and drug responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-bxv0lqa1LN"
      },
      "outputs": [],
      "source": [
        "def plot_cancer_growth_sunburst(data):\n",
        "    # Prepare data for sunburst chart\n",
        "    df_grouped = data.groupby(['Cancer Type (matching TCGA label)', 'Growth Properties']).size().reset_index(name='count')\n",
        "\n",
        "    # Create sunburst chart using plotly express\n",
        "    fig = px.sunburst(\n",
        "        df_grouped,\n",
        "        path=['Cancer Type (matching TCGA label)', 'Growth Properties'],\n",
        "        values='count',\n",
        "        color='count',\n",
        "        color_continuous_scale='Viridis',\n",
        "        title='Cancer Types and Their Growth Properties'\n",
        "    )\n",
        "\n",
        "    fig.update_layout(width=1000, height=1000)\n",
        "    fig.show()\n",
        "\n",
        "plot_cancer_growth_sunburst(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vv2PpLIa1LN"
      },
      "source": [
        "## 4.11. Sankey Diagram for Drug-Target-Pathway Relationship\n",
        "\n",
        "This Sankey diagram visualizes the relationships between drugs, their targets, and the associated pathways. The width of the flows represents the frequency of each relationship in our dataset. This complex visualization helps in understanding how drugs are connected to their molecular targets and the broader cellular pathways they affect. It's particularly useful for identifying drugs that share targets or pathways, which could suggest similar mechanisms of action or potential for drug repurposing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRi5cz2Ca1LN"
      },
      "outputs": [],
      "source": [
        "def plot_drug_target_pathway_sankey(data):\n",
        "    # Prepare data for Sankey diagram\n",
        "    df_grouped = data.groupby(['DRUG_NAME', 'TARGET', 'TARGET_PATHWAY']).size().reset_index(name='count')\n",
        "    df_grouped = df_grouped.sort_values('count', ascending=False).head(50)  # Top 50 combinations\n",
        "\n",
        "    # Create node lists\n",
        "    drugs = df_grouped['DRUG_NAME'].unique().tolist()\n",
        "    targets = df_grouped['TARGET'].unique().tolist()\n",
        "    pathways = df_grouped['TARGET_PATHWAY'].unique().tolist()\n",
        "\n",
        "    # Create node labels and colors\n",
        "    node_labels = drugs + targets + pathways\n",
        "    node_colors = ['#1f77b4'] * len(drugs) + ['#ff7f0e'] * len(targets) + ['#2ca02c'] * len(pathways)\n",
        "\n",
        "    # Create links\n",
        "    source = [drugs.index(drug) for drug in df_grouped['DRUG_NAME']] + \\\n",
        "             [len(drugs) + targets.index(target) for target in df_grouped['TARGET']]\n",
        "    target = [len(drugs) + targets.index(target) for target in df_grouped['TARGET']] + \\\n",
        "             [len(drugs) + len(targets) + pathways.index(pathway) for pathway in df_grouped['TARGET_PATHWAY']]\n",
        "    value = df_grouped['count'].tolist() + df_grouped['count'].tolist()\n",
        "\n",
        "    # Create Sankey diagram\n",
        "    fig = go.Figure(data=[go.Sankey(\n",
        "        node = dict(\n",
        "          pad = 15,\n",
        "          thickness = 20,\n",
        "          line = dict(color = \"black\", width = 0.5),\n",
        "          label = node_labels,\n",
        "          color = node_colors\n",
        "        ),\n",
        "        link = dict(\n",
        "          source = source,\n",
        "          target = target,\n",
        "          value = value\n",
        "    ))])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=\"Drug-Target-Pathway Relationships\",\n",
        "        font_size=10,\n",
        "        width=1200,\n",
        "        height=800\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "plot_drug_target_pathway_sankey(Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkn6Al4ja1LN"
      },
      "source": [
        "# 5. Advanced Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiJD9JOKa1LN"
      },
      "source": [
        "## 5.1. Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDVhvN0ya1LN"
      },
      "outputs": [],
      "source": [
        "# Correlation heatmap of encoded features\n",
        "plt.figure(figsize=(20, 16))\n",
        "correlation_matrix = encoded_data.corr()\n",
        "sns.heatmap(correlation_matrix, cmap='Blues', annot=True)\n",
        "plt.title('Correlation Heatmap of Encoded Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8oR0lyXa1LN"
      },
      "outputs": [],
      "source": [
        "# Check the correlations between all of the features\n",
        "corr_matrix = encoded_data.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(bool))\n",
        "# Find index of feature columns with correlation greater than 0.90\n",
        "to_drop = [column for column in upper.columns if any(upper[column] >= 0.9)]\n",
        "to_drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrua5X0Pa1LN"
      },
      "outputs": [],
      "source": [
        "# Find other pair of correlated features\n",
        "pd.set_option('display.width', 1000)\n",
        "for i in range(len(to_drop)):\n",
        "  print(corr_matrix.loc[corr_matrix[to_drop[i]].abs() > 0.9, corr_matrix[to_drop[i]].abs() > 0.9].to_markdown() , '\\n\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-WIF9ksa1LN"
      },
      "source": [
        "## 5.2. Handling Outliers and Skewness in GDSC Dataset\n",
        "\n",
        "Our approach to handling outliers and skewness in the GDSC dataset is tailored to the specific characteristics of drug response data. We use a three-step process: first, we find outliers for each drug, then we check for outliers and skewness, and finally, we handle them appropriately.\n",
        "\n",
        "### 1. Finding Outliers for Each Drug\n",
        "\n",
        "**Function:** `find_outliers_by_drug()`\n",
        "\n",
        "This function performs the following tasks for each drug and numeric variable:\n",
        "\n",
        "- Identifies outliers using the Interquartile Range (IQR) method.\n",
        "- Calculates the percentage and count of outliers for each drug and variable.\n",
        "- Prints a summary of outliers for each drug and variable.\n",
        "\n",
        "**Why this approach?**\n",
        "- **Drug-specific analysis:** Different drugs may have different distributions of response variables.\n",
        "- **IQR method:** Robust to extreme outliers and doesn't assume a normal distribution.\n",
        "- **Comprehensive overview:** Provides a summary of outliers across all drugs and variables.\n",
        "\n",
        "### 2. Checking Outliers and Skewness\n",
        "\n",
        "**Function:** `check_outliers_and_skewness()`\n",
        "\n",
        "This function performs the following tasks for the first two drugs and each numeric variable:\n",
        "\n",
        "- Calculates skewness.\n",
        "- Identifies outliers using the Interquartile Range (IQR) method.\n",
        "- Visualizes the distribution and box plot of each variable.\n",
        "\n",
        "**Why this approach?**\n",
        "- **Focused analysis:** Examines the first two drugs for a detailed view without overwhelming output.\n",
        "- **Dual visualization:** Provides both histogram and box plot for a comprehensive view of the data distribution.\n",
        "- **Skewness calculation:** Quantifies the asymmetry of the distribution.\n",
        "\n",
        "### 3. Handling Outliers and Skewness\n",
        "\n",
        "**Function:** `handle_outliers_and_skewness()`\n",
        "\n",
        "This function applies the following treatments:\n",
        "\n",
        "1. **Outlier Handling:**\n",
        "   - Uses IQR capping to limit extreme values.\n",
        "   - **Why?** Preserves the data while reducing the impact of extreme outliers.\n",
        "\n",
        "2. **Skewness Handling:**\n",
        "   - Applies no transformation if absolute skewness ≤ 1.\n",
        "   - Attempts Yeo-Johnson transformation if absolute skewness > 1.\n",
        "   - Falls back to log transformation if Yeo-Johnson fails.\n",
        "   - **Why?** Adapts to different levels of skewness and handles both positive and negative values.\n",
        "\n",
        "3. **Visualization:**\n",
        "   - Shows before and after distributions for one example of each transformation type.\n",
        "   - **Why?** Allows for easy assessment of the transformation's effectiveness.\n",
        "\n",
        "**Why this approach?**\n",
        "- **Drug-specific treatment:** Ensures that the unique characteristics of each drug's data are preserved.\n",
        "- **Flexible transformations:** Adapts to different types of skewness in the data.\n",
        "- **Preservation of data:** Uses capping instead of removal for outliers, maintaining sample size.\n",
        "- **Visual confirmation:** Provides immediate feedback on the effectiveness of the transformations.\n",
        "\n",
        "This method allows us to address outliers and skewness issues while maintaining the integrity of the drug-specific patterns in the GDSC dataset. By handling these issues, we improve the reliability of subsequent analyses and ensure that our data meets the assumptions of many statistical methods.\n",
        "\n",
        "**Note:** Due to the high number of drugs in the dataset, we only visualize the distributions and transformations for select examples of each transformation type. This approach allows for a clearer and more concise examination of outliers and skewness while still processing all data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBYHPd-Pa1LN"
      },
      "outputs": [],
      "source": [
        "def find_outliers_by_drug(df, numeric_cols=['LN_IC50', 'AUC', 'Z_SCORE']):\n",
        "    outliers = {}\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique():\n",
        "        drug_data = df[df['DRUG_NAME'] == drug]\n",
        "        drug_outliers = {}\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            v = drug_data[col]\n",
        "            q1 = v.quantile(0.25)\n",
        "            q3 = v.quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "            lower_bound = q1 - 1.5 * iqr\n",
        "            upper_bound = q3 + 1.5 * iqr\n",
        "            outliers_count = ((v < lower_bound) | (v > upper_bound)).sum()\n",
        "            perc = outliers_count * 100.0 / len(drug_data)\n",
        "            drug_outliers[col] = (perc, outliers_count)\n",
        "            print(f\"Drug: {drug}, Column: {col} outliers = {perc:.2f}% ({outliers_count} out of {len(drug_data)})\")\n",
        "\n",
        "        outliers[drug] = drug_outliers\n",
        "\n",
        "    return outliers\n",
        "\n",
        "# Find outliers in the DataFrame for each drug\n",
        "outliers = find_outliers_by_drug(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWhxlmika1LN"
      },
      "outputs": [],
      "source": [
        "def check_outliers_and_skewness(df, numeric_cols):\n",
        "    skewness_info = {}\n",
        "    outlier_info = {}\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique()[:2]:  # Only first two drugs\n",
        "        drug_data = df[df['DRUG_NAME'] == drug]\n",
        "        skewness_info[drug] = {}\n",
        "        outlier_info[drug] = {}\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            # Calculate skewness\n",
        "            col_skewness = skew(drug_data[col].dropna())\n",
        "            skewness_info[drug][col] = col_skewness\n",
        "\n",
        "            # Identify outliers using IQR method\n",
        "            Q1 = drug_data[col].quantile(0.25)\n",
        "            Q3 = drug_data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = drug_data[(drug_data[col] < lower_bound) | (drug_data[col] > upper_bound)][col]\n",
        "            outlier_info[drug][col] = outliers\n",
        "\n",
        "            # Plot distribution and box plot\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "            fig.suptitle(f'Distribution and Box Plot of {col} for {drug}')\n",
        "\n",
        "            # Histogram\n",
        "            sns.histplot(drug_data[col], kde=True, ax=ax1)\n",
        "            ax1.axvline(lower_bound, color='r', linestyle='--', label='IQR bounds')\n",
        "            ax1.axvline(upper_bound, color='r', linestyle='--')\n",
        "            ax1.set_title(f'Histogram (Skewness: {col_skewness:.2f})')\n",
        "            ax1.legend()\n",
        "\n",
        "            # Box plot\n",
        "            sns.boxplot(x=drug_data[col], ax=ax2)\n",
        "            ax2.set_title('Box Plot')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"Drug: {drug}, Column: {col}\")\n",
        "            print(f\"Skewness: {col_skewness:.2f}\")\n",
        "            print(f\"Number of outliers: {len(outliers)}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    return skewness_info, outlier_info\n",
        "\n",
        "\n",
        "numeric_cols = ['LN_IC50', 'AUC', 'Z_SCORE']\n",
        "skewness_info, outlier_info = check_outliers_and_skewness(Data, numeric_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCoCSspca1LN"
      },
      "outputs": [],
      "source": [
        "def check_outliers_and_skewness(df, numeric_cols):\n",
        "    skewness_info = {}\n",
        "    outlier_info = {}\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique()[:2]:  # Only first two drugs\n",
        "        drug_data = df[df['DRUG_NAME'] == drug]\n",
        "        skewness_info[drug] = {}\n",
        "        outlier_info[drug] = {}\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            # Calculate skewness\n",
        "            col_skewness = skew(drug_data[col].dropna())\n",
        "            skewness_info[drug][col] = col_skewness\n",
        "\n",
        "            # Identify outliers using IQR method\n",
        "            Q1 = drug_data[col].quantile(0.25)\n",
        "            Q3 = drug_data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = drug_data[(drug_data[col] < lower_bound) | (drug_data[col] > upper_bound)][col]\n",
        "            outlier_info[drug][col] = outliers\n",
        "\n",
        "            # Create subplot\n",
        "            fig = make_subplots(rows=1, cols=2, subplot_titles=['Histogram', 'Box Plot'])\n",
        "\n",
        "            # Histogram\n",
        "            hist_data = go.Histogram(x=drug_data[col], name='Distribution', opacity=0.7)\n",
        "            fig.add_trace(hist_data, row=1, col=1)\n",
        "\n",
        "            # Add KDE to histogram\n",
        "            kde_x = np.linspace(drug_data[col].min(), drug_data[col].max(), 100)\n",
        "            kde_y = drug_data[col].plot.kde(bw_method=0.5).get_lines()[0].get_ydata()\n",
        "            kde_line = go.Scatter(x=kde_x, y=kde_y, mode='lines', name='KDE', line=dict(color='red'))\n",
        "            fig.add_trace(kde_line, row=1, col=1)\n",
        "\n",
        "            # Add IQR bounds to histogram\n",
        "            fig.add_vline(x=lower_bound, line_dash=\"dash\", line_color=\"green\", row=1, col=1)\n",
        "            fig.add_vline(x=upper_bound, line_dash=\"dash\", line_color=\"green\", row=1, col=1)\n",
        "\n",
        "            # Box plot\n",
        "            box_data = go.Box(y=drug_data[col], name='Box Plot', boxpoints='outliers')\n",
        "            fig.add_trace(box_data, row=1, col=2)\n",
        "\n",
        "            # Update layout\n",
        "            fig.update_layout(\n",
        "                title_text=f'Distribution and Box Plot of {col} for {drug}',\n",
        "                height=500, width=1000,\n",
        "                annotations=[\n",
        "                    dict(\n",
        "                        x=0.25, y=1.05,\n",
        "                        xref='paper', yref='paper',\n",
        "                        text=f'Skewness: {col_skewness:.2f}',\n",
        "                        showarrow=False\n",
        "                    ),\n",
        "                    dict(\n",
        "                        x=0.75, y=1.05,\n",
        "                        xref='paper', yref='paper',\n",
        "                        text=f'Outliers: {len(outliers)}',\n",
        "                        showarrow=False\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            # Show plot\n",
        "            fig.show()\n",
        "\n",
        "            print(f\"Drug: {drug}, Column: {col}\")\n",
        "            print(f\"Skewness: {col_skewness:.2f}\")\n",
        "            print(f\"Number of outliers: {len(outliers)}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    return skewness_info, outlier_info\n",
        "\n",
        "\n",
        "numeric_cols = ['LN_IC50', 'AUC', 'Z_SCORE']\n",
        "skewness_info, outlier_info = check_outliers_and_skewness(Data, numeric_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD5Z_Ww4a1LO"
      },
      "outputs": [],
      "source": [
        "def handle_outliers_and_skewness(df, numeric_cols):\n",
        "    transformation_examples = {'None': None, 'Yeo-Johnson': None, 'Log': None}\n",
        "\n",
        "    for drug in df['DRUG_NAME'].unique():\n",
        "        drug_data = df[df['DRUG_NAME'] == drug].copy()\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            # Calculate initial skewness\n",
        "            initial_skewness = skew(drug_data[col].dropna())\n",
        "\n",
        "            # Handle Outliers: Using IQR capping\n",
        "            Q1 = drug_data[col].quantile(0.25)\n",
        "            Q3 = drug_data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "            # Cap the outliers\n",
        "            drug_data[col] = np.clip(drug_data[col], lower_bound, upper_bound)\n",
        "\n",
        "            # Determine and apply transformation\n",
        "            if abs(initial_skewness) <= 1:\n",
        "                transformation = \"None\"\n",
        "                if transformation_examples['None'] is None:\n",
        "                    transformation_examples['None'] = (drug, col)\n",
        "            elif abs(initial_skewness) > 1:\n",
        "                try:\n",
        "                    # Use Yeo-Johnson transformation (works for negative values)\n",
        "                    drug_data[col], _ = yeojohnson(drug_data[col])\n",
        "                    transformation = \"Yeo-Johnson\"\n",
        "                    if transformation_examples['Yeo-Johnson'] is None:\n",
        "                        transformation_examples['Yeo-Johnson'] = (drug, col)\n",
        "                except:\n",
        "                    # If Yeo-Johnson fails, use log transformation\n",
        "                    drug_data[col] = np.log1p(drug_data[col] - drug_data[col].min() + 1)\n",
        "                    transformation = \"Log\"\n",
        "                    if transformation_examples['Log'] is None:\n",
        "                        transformation_examples['Log'] = (drug, col)\n",
        "\n",
        "            # If this is one of our example transformations, visualize and print info\n",
        "            if (drug, col) in transformation_examples.values():\n",
        "                # Calculate final skewness\n",
        "                final_skewness = skew(drug_data[col].dropna())\n",
        "\n",
        "                # Visualization of before and after\n",
        "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "                sns.histplot(df.loc[df['DRUG_NAME'] == drug, col], kde=True, ax=ax1)\n",
        "                ax1.set_title(f'Original Distribution of {col} for {drug}\\nSkewness: {initial_skewness:.2f}')\n",
        "\n",
        "                sns.histplot(drug_data[col], kde=True, ax=ax2)\n",
        "                ax2.set_title(f'Transformed Distribution of {col} for {drug}\\nTransformation: {transformation}\\nSkewness: {final_skewness:.2f}')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "                print(f\"Drug: {drug}, Column: {col}\")\n",
        "                print(f\"Initial Skewness: {initial_skewness:.2f}\")\n",
        "                print(f\"Final Skewness: {final_skewness:.2f}\")\n",
        "                print(f\"Transformation: {transformation}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "        # Replace the original data with the transformed data\n",
        "        df.loc[df['DRUG_NAME'] == drug, numeric_cols] = drug_data[numeric_cols]\n",
        "\n",
        "    return df, transformation_examples\n",
        "\n",
        "numeric_cols = ['LN_IC50', 'AUC', 'Z_SCORE']\n",
        "gdsc_data, transformation_examples = handle_outliers_and_skewness(Data, numeric_cols)\n",
        "\n",
        "# Print summary of transformation examples\n",
        "print(\"\\nTransformation Examples:\")\n",
        "for transform, example in transformation_examples.items():\n",
        "    if example:\n",
        "        print(f\"{transform}: Drug - {example[0]}, Column - {example[1]}\")\n",
        "    else:\n",
        "        print(f\"{transform}: No example found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugcCi6VrKhuz"
      },
      "source": [
        "## 5.3. Training and Evaluating Machine Learning Models on GDSC Dataset\n",
        "\n",
        "Our approach to training and evaluating machine learning models on the GDSC dataset is structured to handle the unique characteristics of genomic and drug response data. We follow a comprehensive four-step process: model selection, hyperparameter tuning, evaluation, and model comparison. This approach ensures robust and interpretable results for predicting drug sensitivity.\n",
        "\n",
        "### 1. Model Selection\n",
        "\n",
        "**Function:** `select_models()`\n",
        "\n",
        "This function selects and initializes four key models for drug response prediction:\n",
        "- **Random Forest Regressor**\n",
        "- **Decision Tree Regressor**\n",
        "- **Support Vector Machine (SVM)**\n",
        "- **Linear Regression**\n",
        "\n",
        "**Why this approach?**\n",
        "- **Diverse modeling strategies**: These models cover different algorithmic strategies, from tree-based methods to linear approaches.\n",
        "- **Interpretability and predictive power**: Models like Decision Trees and Linear Regression provide interpretable results, while Random Forest and SVM are known for strong predictive capabilities.\n",
        "- **Suitability for continuous variables**: All selected models are well-suited for continuous target variables, like drug response metrics.\n",
        "\n",
        "### 2. Hyperparameter Tuning\n",
        "\n",
        "**Function:** `tune_hyperparameters()`\n",
        "\n",
        "This function performs the following for each model:\n",
        "- Applies grid search with cross-validation to find optimal hyperparameters.\n",
        "- Evaluates each combination of parameters and identifies the best-performing set.\n",
        "  \n",
        "**Why this approach?**\n",
        "- **Fine-tuned performance**: Grid search allows us to systematically explore parameter values, improving each model's predictive power.\n",
        "- **Cross-validation**: Enhances robustness by averaging performance over multiple training/test splits.\n",
        "- **Model-specific tuning**: Each model has its own set of hyperparameters (e.g., `n_estimators` for Random Forest and `kernel` for SVM), ensuring tailored optimization.\n",
        "\n",
        "### 3. Model Evaluation\n",
        "\n",
        "**Function:** `evaluate_models()`\n",
        "\n",
        "This function evaluates each model on test data using the following metrics:\n",
        "- **Mean Squared Error (MSE)**\n",
        "- **R-squared (R²)**\n",
        "\n",
        "Additionally, it provides:\n",
        "- **Cross-Validation Scores**: For a more reliable performance estimate.\n",
        "- **Prediction vs. Actual Plots**: To visually assess each model’s prediction accuracy.\n",
        "\n",
        "**Why this approach?**\n",
        "- **Comprehensive evaluation**: MSE and R² offer insights into model accuracy and goodness-of-fit.\n",
        "- **Cross-validation**: Reduces the risk of overfitting by providing performance estimates across multiple data splits.\n",
        "- **Visual confirmation**: Prediction plots reveal model performance visually, highlighting any systematic prediction biases.\n",
        "\n",
        "### 4. Model Comparison\n",
        "\n",
        "**Function:** `compare_models()`\n",
        "\n",
        "This function creates a summary of each model’s performance, including:\n",
        "- **Average Cross-Validation R²**\n",
        "- **Test MSE**\n",
        "- **Test R²**\n",
        "\n",
        "It then visualizes these metrics with bar plots to compare models side-by-side.\n",
        "\n",
        "**Why this approach?**\n",
        "- **Objective comparison**: Summarizes model performance on key metrics, helping to identify the best-suited model.\n",
        "- **Visual clarity**: Bar plots make it easy to interpret differences in model performance and identify the top-performing approach.\n",
        "- **Balanced interpretation**: By comparing multiple metrics, we avoid focusing solely on a single performance aspect, offering a well-rounded view of each model.\n",
        "\n",
        "### 5. Visualization of Model Performance\n",
        "\n",
        "**Function:** `plot_model_performance()`\n",
        "\n",
        "This function performs the following tasks:\n",
        "1. **Prediction vs. Actual Scatter Plot**: For each model, it plots the test data's actual values against the predictions.\n",
        "2. **Model Comparison Bar Plots**: It shows comparative metrics, such as Mean Cross-Validation R², Test MSE, and Test R² for each model.\n",
        "\n",
        "**Why this approach?**\n",
        "- **Detailed insight into model accuracy**: Prediction vs. Actual plots highlight the fit quality and any potential bias in predictions.\n",
        "- **Clear model ranking**: Bar plots provide a straightforward visual comparison of model strengths, allowing for quick identification of the best models.\n",
        "\n",
        "### Summary\n",
        "\n",
        "This approach enables a thorough exploration and comparison of machine learning models on the GDSC dataset, ensuring that we select the most accurate and reliable model for drug sensitivity prediction. By selecting diverse models, optimizing hyperparameters, and evaluating with multiple metrics, we achieve a balanced and comprehensive assessment of model performance. This rigorous process improves the predictive reliability of our results, providing valuable insights into genomic drug sensitivity patterns in cancer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJQm5p1_LrrG"
      },
      "outputs": [],
      "source": [
        "print(merged_data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qwL_rmXkrGm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load and prepare the data\n",
        "target = 'LN_IC50'\n",
        "features = ['Gene Expression', 'Methylation', 'Cancer Type (matching TCGA label)',\n",
        "            'PATHWAY_NAME', 'Microsatellite instability Status (MSI)',\n",
        "            'GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2']\n",
        "\n",
        "# Assuming merged_data is already loaded and preprocessed\n",
        "X = merged_data[features]\n",
        "y = merged_data[target]\n",
        "\n",
        "# Convert relevant columns to numeric if not already (for Gene Expression and Methylation)\n",
        "X['Gene Expression'] = pd.to_numeric(X['Gene Expression'], errors='coerce')\n",
        "X['Methylation'] = pd.to_numeric(X['Methylation'], errors='coerce')\n",
        "\n",
        "# Encode categorical variables and handle missing values\n",
        "categorical_columns = ['Cancer Type (matching TCGA label)', 'PATHWAY_NAME',\n",
        "                       'Microsatellite instability Status (MSI)',\n",
        "                       'GDSC Tissue descriptor 1', 'GDSC Tissue descriptor 2']\n",
        "\n",
        "# Convert categorical columns to 'category' dtype if they are not already\n",
        "for col in categorical_columns:\n",
        "    X[col] = X[col].astype('category')\n",
        "\n",
        "# Convert categorical columns to numeric using 'pd.get_dummies'\n",
        "X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Handle missing values in numerical columns using SimpleImputer in a pipeline\n",
        "numerical_columns = X.select_dtypes(include=[np.number]).columns\n",
        "X[numerical_columns] = X[numerical_columns].fillna(X[numerical_columns].median())\n",
        "\n",
        "# Handle missing values in the target variable (y) by filling NaN with the median\n",
        "y.fillna(y.median(), inplace=True)\n",
        "\n",
        "# Verify that there are no string columns left in X\n",
        "assert X.select_dtypes(include=[object]).shape[1] == 0, \"There are still string columns in X!\"\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
        "\n",
        "# Define models and pipelines with scaling and imputation for applicable models\n",
        "pipelines = {\n",
        "    \"Random Forest\": Pipeline([('imputer', SimpleImputer(strategy='median')), ('model', RandomForestRegressor(random_state=42))]),\n",
        "    \"Decision Tree\": Pipeline([('imputer', SimpleImputer(strategy='median')), ('model', DecisionTreeRegressor(random_state=42))]),\n",
        "    \"SVM\": Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler()), ('model', SVR())]),\n",
        "    \"Linear Regression\": Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler()), ('model', LinearRegression())])\n",
        "}\n",
        "\n",
        "# Hyperparameter grids (reduced for testing)\n",
        "param_grids = {\n",
        "    \"Random Forest\": {\"model__n_estimators\": [50, 100]},\n",
        "    \"Decision Tree\": {\"model__max_depth\": [None, 10]},\n",
        "    \"SVM\": {\"model__kernel\": [\"linear\"], \"model__C\": [1]},\n",
        "    \"Linear Regression\": {}  # No hyperparameters for tuning\n",
        "}\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Function to evaluate model with cross-validation\n",
        "def evaluate_model(y_true, y_pred, model_name, cv_scores):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {\"Model\": model_name, \"MSE\": mse, \"R²\": r2, \"CV R² (Mean)\": np.mean(cv_scores)}\n",
        "\n",
        "# Train, tune, and evaluate each model\n",
        "for model_name, pipeline in pipelines.items():\n",
        "    # Hyperparameter tuning with GridSearchCV\n",
        "    grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=3, scoring=\"r2\", n_jobs=-1, verbose=3)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Cross-validation scores for evaluation\n",
        "    cv_scores = cross_val_score(best_model, X_train, y_train, cv=3, scoring='r2')\n",
        "\n",
        "    # Predict and evaluate\n",
        "    predictions = best_model.predict(X_test)\n",
        "    evaluation = evaluate_model(y_test, predictions, model_name, cv_scores)\n",
        "    evaluation[\"Best Params\"] = best_params\n",
        "    results.append(evaluation)\n",
        "\n",
        "    # Visualization: Prediction vs. Actual and Residual Plot\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Prediction vs Actual\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(y_test, predictions, alpha=0.5)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', color=\"red\", lw=2)\n",
        "    plt.xlabel(\"Actual Values\")\n",
        "    plt.ylabel(\"Predicted Values\")\n",
        "    plt.title(f\"{model_name} Predictions vs Actual\")\n",
        "\n",
        "    # Residual Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    residuals = y_test - predictions\n",
        "    plt.scatter(predictions, residuals, alpha=0.5)\n",
        "    plt.axhline(0, color='red', linestyle='--')\n",
        "    plt.xlabel(\"Predicted Values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.title(f\"{model_name} Residuals\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Create a DataFrame to compare model results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Model Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# Visualize Comparison of Model Performance Metrics\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot Test MSE for each model\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='MSE', data=results_df)\n",
        "plt.title(\"Model Comparison: Test Mean Squared Error (MSE)\")\n",
        "plt.ylabel(\"Test MSE\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.show()\n",
        "\n",
        "# Plot Test R-squared for each model\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='R²', data=results_df)\n",
        "plt.title(\"Model Comparison: Test R-squared\")\n",
        "plt.ylabel(\"Test R-squared\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.show()\n",
        "\n",
        "# Plot Cross-Validation R-squared for each model\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='CV R² (Mean)', data=results_df)\n",
        "plt.title(\"Model Comparison: Cross-Validation R-squared (Mean)\")\n",
        "plt.ylabel(\"Mean CV R-squared\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 5535401,
          "sourceId": 9167838,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}